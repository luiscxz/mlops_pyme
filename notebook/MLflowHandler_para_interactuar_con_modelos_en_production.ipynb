{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c513077",
   "metadata": {},
   "source": [
    "A continuación, crearemos una clase encargada de establecer la conexión con MLflow, en particular con su componente Model Registry, el repositorio donde se almacenan los modelos versionados y organizados por etapas como “Staging” o “Production”.\n",
    "\n",
    "Esta clase incluye los siguientes métodos:\n",
    "- **__init__**: Inicia el objeto con la configuración de conexión al registro de modelos de mlflow\n",
    "- **check_mlflow_health**: Se encarga de comprobar si el servidor MLflow está disponible y responde correctamente.\n",
    "- **check_registry_health**: Se encarga de consultar el registro de modelos en MLflow para comprobar que existan modelos en producción.\n",
    "- **list_production_models**: Se encarga de listar todos los modelos registrados en MLflow que tienen versiones en producción.\n",
    "- **get_production_model**: Se encarga de cargar un modelo en específico que esté en etapa de producción.\n",
    "- **get_model_details**: Obtiene detalles de los modelos registrados en MLflow.\n",
    "- **debug_registry**: Obtiene información completa de los modelos registrados en MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "class MlflowHandler:\n",
    "    \"\"\"\n",
    "    Se encarga de establecer conexión al registro de modelos de MLflow\n",
    "    para seleccionar los modelos por verisón y etapas.\n",
    "    \"\"\"\n",
    "    def __init__(self, tracking_uri=\"http://localhost:5000\",\n",
    "                 s3_endpoint=None, aws_access_key=None, aws_secret_key=None):\n",
    "        \"\"\"\n",
    "        Configura la conexión con el servidor de MLflow y opcionalmente S3/MinIO.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        tracking_uri: str\n",
    "            URL del servidor MLflow, por defecto es http://localhost:5000\n",
    "        s3_endpoint: str, optional\n",
    "            Endpoint de S3/MinIO\n",
    "        aws_access_key: str, optional\n",
    "            Access key de S3/MinIO\n",
    "        aws_secret_key: str, optional\n",
    "            Secret key de S3/MinIO\n",
    "        \"\"\"\n",
    "        # Configurar credenciales de S3/MinIO antes de inicializar MLflow\n",
    "        if s3_endpoint and aws_access_key and aws_secret_key:\n",
    "            os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = s3_endpoint\n",
    "            os.environ[\"AWS_ACCESS_KEY_ID\"] = aws_access_key\n",
    "            os.environ[\"AWS_SECRET_ACCESS_KEY\"] = aws_secret_key\n",
    "\n",
    "        self.client = MlflowClient(tracking_uri=tracking_uri)\n",
    "        mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    def check_mlflow_health(self):\n",
    "        \"\"\"\n",
    "        Comprueba si el servidor MLflow está disponible y responde\n",
    "        correctamente.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict: Estado del servicio con estructura {\n",
    "            'healthy': bool,\n",
    "            'message': str,\n",
    "            'experiment_count': int\n",
    "        }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            experiments = self.client.search_experiments()\n",
    "            return {\n",
    "                'healthy': True,\n",
    "                'message': 'El servicio MLflow es receptivo',\n",
    "                'experiment_count': len(experiments)\n",
    "            }\n",
    "        except ConnectionError as e:\n",
    "            return {\n",
    "                'healthy': False,\n",
    "                'message': f'Connection error: {e}',\n",
    "                'experiment_count': 0\n",
    "            }\n",
    "    def check_registry_health(self):\n",
    "        \"\"\"\n",
    "        Este método consulta el registro de modelos de mlflow para comprobar si existe \n",
    "        al menos una versión de modelo en el estado \"Production\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "         bool\n",
    "            - True si al menos un modelo tiene una versión en producción.\n",
    "            - False si no existen versiones en producción.\n",
    "\n",
    "        Raise\n",
    "        -----\n",
    "        RuntimeError\n",
    "            Si ocurre un error al intentar acceder o consultar el registro de modelos.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            registered_models = self.client.search_registered_models()\n",
    "            has_production_models = False\n",
    "            for model in registered_models:\n",
    "                # Verificar si este modelo tiene versión en producción\n",
    "                for version in model.latest_versions:\n",
    "                    if version.current_stage == \"Production\":\n",
    "                        has_production_models = True\n",
    "                        break\n",
    "                if has_production_models:\n",
    "                    break\n",
    "            return has_production_models\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Error al chequear registro\") from e  \n",
    "    \n",
    "    def list_production_models(self):\n",
    "        \"\"\"\n",
    "        Lista todos los modelos registrados que tienen versiones en producción.\n",
    "\n",
    "        Este método consulta el registro de modelos en MLflow y devuelve \n",
    "        información básica sobre cada modelo que cuenta con al menos una \n",
    "        versión en el estado \"Production\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[dict]:\n",
    "            Una lista de diccionarios, donde cada elemento representa un modelo\n",
    "            con las siguientes claves:\n",
    "    \n",
    "            - \"name\" (str): nombre del modelo registrado.  \n",
    "            - \"version\" (str): número de versión en producción.  \n",
    "            - \"description\" (str | None): descripción asociada a la versión. \n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        Exception\n",
    "            Si ocurre algún error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            models = self.client.search_registered_models()\n",
    "            production_models = []\n",
    "            \n",
    "            for model in models:\n",
    "                for version in model.latest_versions:\n",
    "                    if version.current_stage == \"Production\":\n",
    "                        production_models.append({\n",
    "                            \"name\": model.name,\n",
    "                            \"version\": version.version,\n",
    "                            \"description\": version.description\n",
    "                        })\n",
    "            return production_models\n",
    "        except Exception as e:\n",
    "            return [f\"Error: {e}\"]    \n",
    "    \n",
    "    def get_production_model(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Carga un modelo específico desde el Model Registry en la etapa \"Production\".\n",
    "\n",
    "        Este método busca el modelo indicado en el registro de MLflow y carga \n",
    "        la versión que se encuentra en el estado \"Production\". \n",
    "        Si el modelo no existe o no se puede cargar, se lanza una excepción.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_name: str\n",
    "            nombre del modelo registrado en MLflow.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            mlflow.pyfunc.PyFuncModel: Instancia del modelo cargado desde MLflow.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "            ValueError: Si el modelo no existe en el registro.\n",
    "            RuntimeError: Si ocurre un error al intentar cargar el modelo desde MLflow.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model_details = self.get_model_details(model_name)\n",
    "            if not model_details:\n",
    "                raise Exception(f\"Modelo {model_name} no encontrado en el registry\")\n",
    "            \n",
    "            model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/production\")\n",
    "            logger.info(f\"Modelo '{model_name}' cargado exitosamente desde Production.\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cargando modelo '{model_name}' desde Production: {e}\")\n",
    "            raise RuntimeError(f\"Error cargando modelo '{model_name}' desde Production.\") from e\n",
    "        \n",
    "    def get_production_sklearn_model(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Carga un modelo de scikit-learn desde el Model Registry de MLflow \n",
    "        en la etapa \"Production\".\n",
    "\n",
    "        Este método obtiene el modelo registrado en MLflow usando el flavor\n",
    "        específico de `mlflow.sklearn`, devolviendo el objeto original de \n",
    "        scikit-learn. A diferencia del modelo genérico `PyFuncModel`, este \n",
    "        permite acceder a métodos nativos como `predict_proba()`, `score()` \n",
    "        y otros disponibles en la clase base de scikit-learn.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Nombre del modelo registrado en MLflow que se desea cargar.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sklearn.base.BaseEstimator\n",
    "            Instancia del modelo de scikit-learn cargado desde MLflow en la \n",
    "            etapa \"Production\".\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            Si ocurre un error durante la carga del modelo o si no puede \n",
    "            accederse al registro de MLflow.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model = mlflow.sklearn.load_model(f\"models:/{model_name}/Production\")\n",
    "            logger.info(f\"Modelo sklearn '{model_name}' cargado desde Production.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cargando modelo sklearn '{model_name}': {e}\")\n",
    "            raise RuntimeError(f\"Error cargando modelo sklearn '{model_name}'\") from e\n",
    "\n",
    "    def get_model_details(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Obtiene los detalles de un modelo específico registrado en MLflow.\n",
    "\n",
    "        Este método consulta el registro de modelos (Model Registry) de MLflow\n",
    "        para recuperar información del modelo identificado por `model_name`.\n",
    "        Retorna un diccionario con el nombre del modelo y una lista de sus\n",
    "        versiones más recientes, incluyendo su etapa (stage) y descripción.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_name: str\n",
    "            Nombre del modelo registrado en MLflow\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        dict\n",
    "            Un diccionario con información relevante del modelo\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        None explícitamente.\n",
    "            (Los errores se registran mediante `logger.error` y la función devuelve `None`.)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model = self.client.get_registered_model(model_name)\n",
    "            details = {\n",
    "                \"name\": model.name,\n",
    "                \"versions\": []\n",
    "            }\n",
    "            \n",
    "            for version in model.latest_versions:\n",
    "                details[\"versions\"].append({\n",
    "                    \"version\": version.version,\n",
    "                    \"stage\": version.current_stage,\n",
    "                    \"description\": version.description\n",
    "                })\n",
    "            \n",
    "            return details\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error '{model_name}' no encontrado: {e}\")\n",
    "            return None \n",
    "           \n",
    "    def debug_registry(self):\n",
    "        \"\"\"\n",
    "        Obtiene información completa del estado actual del Model Registry de MLflow.\n",
    "\n",
    "        Esta función se utiliza con fines de depuración o auditoría para inspeccionar \n",
    "        el estado completo del registro de modelos. Recupera todos los modelos \n",
    "        registrados y sus versiones más recientes, incluyendo su nombre, descripción, \n",
    "        estado, etapa (stage) y versiones que están actualmente en producción.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            dict: Diccionario con información general y detallada del registro.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        None explícitamente.\n",
    "            (Los errores se capturan internamente y se devuelven en la respuesta como texto.)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_models = self.client.search_registered_models()\n",
    "            debug_info = {\n",
    "                \"total_models\": len(all_models),\n",
    "                \"models\": [],\n",
    "                \"production_models\": []\n",
    "            }\n",
    "            \n",
    "            for model in all_models:\n",
    "                model_info = {\n",
    "                    \"name\": model.name,\n",
    "                    \"description\": model.description,\n",
    "                    \"versions\": []\n",
    "                }\n",
    "                \n",
    "                for version in model.latest_versions:\n",
    "                    version_info = {\n",
    "                        \"version\": version.version,\n",
    "                        \"stage\": version.current_stage,\n",
    "                        \"status\": version.status\n",
    "                    }\n",
    "                    model_info[\"versions\"].append(version_info)\n",
    "                    \n",
    "                    if version.current_stage == \"Production\":\n",
    "                        debug_info[\"production_models\"].append(f\"{model.name} v{version.version}\")\n",
    "                \n",
    "                debug_info[\"models\"].append(model_info)\n",
    "            \n",
    "            return debug_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Debug failed: {e}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788f1b5",
   "metadata": {},
   "source": [
    "Probemos la clase y verifiquemos su funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bea697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'healthy': True,\n",
       " 'message': 'El servicio MLflow es receptivo',\n",
       " 'experiment_count': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = MlflowHandler(\n",
    "    tracking_uri=\"http://localhost:5000\",\n",
    "    s3_endpoint=\"http://localhost:6000\",\n",
    "    aws_access_key=\"minio\",\n",
    "    aws_secret_key=\"minio_123\"\n",
    ")\n",
    "handler.check_mlflow_health() # verifiquemos conexión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b8be2",
   "metadata": {},
   "source": [
    "Perfecto, veamos si hay modelos en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326d3fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.check_registry_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76199d",
   "metadata": {},
   "source": [
    "Ok, vemos que True indica que existen modelos en producción. Veamos cuál es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e99254e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'DecisionTree_CreditRiskModel', 'version': '2', 'description': ''}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.list_production_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb30d5",
   "metadata": {},
   "source": [
    "Veamos los detalles del modelo que hay en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dfdece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DecisionTree_CreditRiskModel',\n",
       " 'versions': [{'version': '6', 'stage': 'None', 'description': ''},\n",
       "  {'version': '2', 'stage': 'Production', 'description': ''}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.get_model_details(model_name=\"DecisionTree_CreditRiskModel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0355d",
   "metadata": {},
   "source": [
    "carguemos un modelo desde producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c1e91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7fdca38e2db4fb996e14350d0f9ebd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo = handler.get_production_sklearn_model(model_name=\"DecisionTree_CreditRiskModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff3c6f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>historial_pagos_atrasados</th>\n",
       "      <th>calificacion_buro</th>\n",
       "      <th>monto_solicitado_mxn</th>\n",
       "      <th>ratio_deuda_ingresos</th>\n",
       "      <th>carga_total_ingresos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100790.96</td>\n",
       "      <td>0.722558</td>\n",
       "      <td>0.739974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>616564.64</td>\n",
       "      <td>0.840515</td>\n",
       "      <td>1.061708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>177995.46</td>\n",
       "      <td>0.623165</td>\n",
       "      <td>1.070324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>91935.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1006577.05</td>\n",
       "      <td>0.756672</td>\n",
       "      <td>0.948822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   historial_pagos_atrasados  calificacion_buro  monto_solicitado_mxn  \\\n",
       "0                          0                  1             100790.96   \n",
       "1                          1                  3             616564.64   \n",
       "2                          1                  2             177995.46   \n",
       "3                          3                  0              91935.97   \n",
       "4                          1                  3            1006577.05   \n",
       "\n",
       "   ratio_deuda_ingresos  carga_total_ingresos  \n",
       "0              0.722558              0.739974  \n",
       "1              0.840515              1.061708  \n",
       "2              0.623165              1.070324  \n",
       "3                   NaN                   NaN  \n",
       "4              0.756672              0.948822  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data ={\n",
    "    \"historial_pagos_atrasados\": [0, 1, 1, 3, 1],\n",
    "    \"calificacion_buro\": [1, 3, 2, 0, 3],\n",
    "    \"monto_solicitado_mxn\": [100790.96, 616564.64, 177995.46, 91935.97, 1006577.05],\n",
    "    \"ratio_deuda_ingresos\": [0.722558, 0.840515, 0.623165, np.nan, 0.756672],\n",
    "    \"carga_total_ingresos\": [0.739974, 1.061708, 1.070324, np.nan, 0.948822]\n",
    "}\n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b53adab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82644628, 0.17355372],\n",
       "       [0.38095238, 0.61904762],\n",
       "       [0.82644628, 0.17355372],\n",
       "       [0.58139535, 0.41860465],\n",
       "       [0.38095238, 0.61904762]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones = modelo.predict_proba(data)\n",
    "predicciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
