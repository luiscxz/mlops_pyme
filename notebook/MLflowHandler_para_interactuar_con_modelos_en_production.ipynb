{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c513077",
   "metadata": {},
   "source": [
    "A continuación, crearemos una clase encargada de establecer la conexión con MLflow, en particular con su componente Model Registry, el repositorio donde se almacenan los modelos versionados y organizados por etapas como “Staging” o “Production”.\n",
    "\n",
    "Esta clase incluye los siguientes métodos:\n",
    "- **__init__**: Inicia el objeto con la configuración de conexión al registro de modelos de mlflow\n",
    "- **check_mlflow_health**: Se encarga de comprobar si el servidor MLflow está disponible y responde correctamente.\n",
    "- **check_registry_health**: Se encarga de consultar el registro de modelos en MLflow para comprobar que existan modelos en producción.\n",
    "- **list_production_models**: Se encarga de listar todos los modelos registrados en MLflow que tienen versiones en producción.\n",
    "- **get_production_model**: Se encarga de cargar un modelo en específico que esté en etapa de producción.\n",
    "- **get_model_details**: Obtiene detalles de los modelos registrados en MLflow.\n",
    "- **debug_registry**: Obtiene información completa de los modelos registrados en MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf8087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "import mlflow\n",
    "from mlflow.pyfunc import PyFuncModel\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "class MlflowHandler:\n",
    "    \"\"\"\n",
    "    Se encarga de establecer conexión al registro de modelos de MLflow\n",
    "    para seleccionar los modelos por verisón y etapas.\n",
    "    \"\"\"\n",
    "    def __init__(self,tracking_uri=\"http://localhost:5000\"):\n",
    "        \"\"\"\n",
    "        Configura la conexión con el servidor de MLflow\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        tracking_uri: str\n",
    "            URL del servidor MLflow, por defecto es http://localhost:5000\n",
    "        \"\"\"\n",
    "        self.client = MlflowClient(tracking_uri=tracking_uri)\n",
    "        mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    def check_mlflow_health(self):\n",
    "        \"\"\"\n",
    "        Comprueba si el servidor MLflow está disponible y responde\n",
    "        correctamente.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict: Estado del servicio con estructura {\n",
    "            'healthy': bool,\n",
    "            'message': str,\n",
    "            'experiment_count': int\n",
    "        }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            experiments = self.client.search_experiments()\n",
    "            return {\n",
    "                'healthy': True,\n",
    "                'message': 'El servicio MLflow es receptivo',\n",
    "                'experiment_count': len(experiments)\n",
    "            }\n",
    "        except ConnectionError as e:\n",
    "            return {\n",
    "                'healthy': False,\n",
    "                'message': f'Connection error: {e}',\n",
    "                'experiment_count': 0\n",
    "            }\n",
    "    def check_registry_health(self):\n",
    "        \"\"\"\n",
    "        Este método consulta el registro de modelos de mlflow para comprobar si existe \n",
    "        al menos una versión de modelo en el estado \"Production\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "         bool\n",
    "            - True si al menos un modelo tiene una versión en producción.\n",
    "            - False si no existen versiones en producción.\n",
    "\n",
    "        Raise\n",
    "        -----\n",
    "        RuntimeError\n",
    "            Si ocurre un error al intentar acceder o consultar el registro de modelos.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            registered_models = self.client.search_registered_models()\n",
    "            has_production_models = False\n",
    "            for model in registered_models:\n",
    "                # Verificar si este modelo tiene versión en producción\n",
    "                for version in model.latest_versions:\n",
    "                    if version.current_stage == \"Production\":\n",
    "                        has_production_models = True\n",
    "                        break\n",
    "                if has_production_models:\n",
    "                    break\n",
    "            return has_production_models\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Error al chequear registro\") from e  \n",
    "    \n",
    "    def list_production_models(self):\n",
    "        \"\"\"\n",
    "        Lista todos los modelos registrados que tienen versiones en producción.\n",
    "\n",
    "        Este método consulta el registro de modelos en MLflow y devuelve \n",
    "        información básica sobre cada modelo que cuenta con al menos una \n",
    "        versión en el estado \"Production\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[dict]:\n",
    "            Una lista de diccionarios, donde cada elemento representa un modelo\n",
    "            con las siguientes claves:\n",
    "    \n",
    "            - \"name\" (str): nombre del modelo registrado.  \n",
    "            - \"version\" (str): número de versión en producción.  \n",
    "            - \"description\" (str | None): descripción asociada a la versión. \n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        Exception\n",
    "            Si ocurre algún error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            models = self.client.search_registered_models()\n",
    "            production_models = []\n",
    "            \n",
    "            for model in models:\n",
    "                for version in model.latest_versions:\n",
    "                    if version.current_stage == \"Production\":\n",
    "                        production_models.append({\n",
    "                            \"name\": model.name,\n",
    "                            \"version\": version.version,\n",
    "                            \"description\": version.description\n",
    "                        })\n",
    "            return production_models\n",
    "        except Exception as e:\n",
    "            return [f\"Error: {e}\"]    \n",
    "    \n",
    "    def get_production_model(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Carga un modelo específico desde el Model Registry en la etapa \"Production\".\n",
    "\n",
    "        Este método busca el modelo indicado en el registro de MLflow y carga \n",
    "        la versión que se encuentra en el estado \"Production\". \n",
    "        Si el modelo no existe o no se puede cargar, se lanza una excepción.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_name: str\n",
    "            nombre del modelo registrado en MLflow.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "            mlflow.pyfunc.PyFuncModel: Instancia del modelo cargado desde MLflow.\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "            ValueError: Si el modelo no existe en el registro.\n",
    "            RuntimeError: Si ocurre un error al intentar cargar el modelo desde MLflow.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model_details = self.get_model_details(model_name)\n",
    "            if not model_details:\n",
    "                raise Exception(f\"Modelo {model_name} no encontrado en el registry\")\n",
    "            \n",
    "            model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/production\")\n",
    "            logger.info(f\"Modelo '{model_name}' cargado exitosamente desde Production.\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cargando modelo '{model_name}' desde Production: {e}\")\n",
    "            raise RuntimeError(f\"Error cargando modelo '{model_name}' desde Production.\") from e\n",
    "\n",
    "\n",
    "    def get_model_details(self, model_name: str):\n",
    "        \"\"\"\n",
    "        Obtiene los detalles de un modelo específico registrado en MLflow.\n",
    "\n",
    "        Este método consulta el registro de modelos (Model Registry) de MLflow\n",
    "        para recuperar información del modelo identificado por `model_name`.\n",
    "        Retorna un diccionario con el nombre del modelo y una lista de sus\n",
    "        versiones más recientes, incluyendo su etapa (stage) y descripción.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_name: str\n",
    "            Nombre del modelo registrado en MLflow\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        dict\n",
    "            Un diccionario con información relevante del modelo\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        None explícitamente.\n",
    "            (Los errores se registran mediante `logger.error` y la función devuelve `None`.)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model = self.client.get_registered_model(model_name)\n",
    "            details = {\n",
    "                \"name\": model.name,\n",
    "                \"versions\": []\n",
    "            }\n",
    "            \n",
    "            for version in model.latest_versions:\n",
    "                details[\"versions\"].append({\n",
    "                    \"version\": version.version,\n",
    "                    \"stage\": version.current_stage,\n",
    "                    \"description\": version.description\n",
    "                })\n",
    "            \n",
    "            return details\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error '{model_name}' no encontrado: {e}\")\n",
    "            return None \n",
    "           \n",
    "    def debug_registry(self):\n",
    "        \"\"\"\n",
    "        Obtiene información completa del estado actual del Model Registry de MLflow.\n",
    "\n",
    "        Esta función se utiliza con fines de depuración o auditoría para inspeccionar \n",
    "        el estado completo del registro de modelos. Recupera todos los modelos \n",
    "        registrados y sus versiones más recientes, incluyendo su nombre, descripción, \n",
    "        estado, etapa (stage) y versiones que están actualmente en producción.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            dict: Diccionario con información general y detallada del registro.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        None explícitamente.\n",
    "            (Los errores se capturan internamente y se devuelven en la respuesta como texto.)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_models = self.client.search_registered_models()\n",
    "            debug_info = {\n",
    "                \"total_models\": len(all_models),\n",
    "                \"models\": [],\n",
    "                \"production_models\": []\n",
    "            }\n",
    "            \n",
    "            for model in all_models:\n",
    "                model_info = {\n",
    "                    \"name\": model.name,\n",
    "                    \"description\": model.description,\n",
    "                    \"versions\": []\n",
    "                }\n",
    "                \n",
    "                for version in model.latest_versions:\n",
    "                    version_info = {\n",
    "                        \"version\": version.version,\n",
    "                        \"stage\": version.current_stage,\n",
    "                        \"status\": version.status\n",
    "                    }\n",
    "                    model_info[\"versions\"].append(version_info)\n",
    "                    \n",
    "                    if version.current_stage == \"Production\":\n",
    "                        debug_info[\"production_models\"].append(f\"{model.name} v{version.version}\")\n",
    "                \n",
    "                debug_info[\"models\"].append(model_info)\n",
    "            \n",
    "            return debug_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Debug failed: {e}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7788f1b5",
   "metadata": {},
   "source": [
    "Probemos la clase y verifiquemos su funcionamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bea697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'healthy': True,\n",
       " 'message': 'El servicio MLflow es receptivo',\n",
       " 'experiment_count': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = MlflowHandler(tracking_uri=\"http://localhost:5000\")\n",
    "handler.check_mlflow_health() # verifiquemos conexión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593b8be2",
   "metadata": {},
   "source": [
    "Perfecto, veamos si hay modelos en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326d3fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.check_registry_health()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76199d",
   "metadata": {},
   "source": [
    "Ok, vemos que True indica que existen modelos en producción. Veamos cuál es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e99254e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'DecisionTree_CreditRiskModel', 'version': '2', 'description': ''}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.list_production_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb30d5",
   "metadata": {},
   "source": [
    "Veamos los detalles del modelo que hay en producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dfdece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'DecisionTree_CreditRiskModel',\n",
       " 'versions': [{'version': '5', 'stage': 'None', 'description': ''},\n",
       "  {'version': '2', 'stage': 'Production', 'description': ''}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler.get_model_details(model_name=\"DecisionTree_CreditRiskModel\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
