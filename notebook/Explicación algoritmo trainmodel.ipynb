{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "502e55b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0064d77",
   "metadata": {},
   "source": [
    "A continuaci√≥n, se crea la clase TrainModel, cuya funci√≥n principal es entrenar un modelo de machine learning. Para ello, carga el conjunto de datos de entrenamiento y el conjunto de evaluaci√≥n del desempe√±o, empleando un pipeline de scikit-learn para escalar los datos y entrenar un √°rbol de decisi√≥n. Los m√©todos encargados de realizar estos procesos son los siguientes:\n",
    "\n",
    "- **load_dataset**: Se encarga de leer el dataset utilizado para entrenamiento.\n",
    "- **load_test_dataset** Se encarga de leer el dataset utilizado para evaluar el modelo.\n",
    "- **train_pipeline**: Se encarga de escalar los datos y entrenar el modelo utilizando pipeline de scikit-learn.\n",
    "- **test_pipeline** Se encarga de evaluar el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743d9fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    \"\"\"\n",
    "    Clase encargada de entrenar y evaluar modelos de ml\n",
    "    \"\"\"\n",
    "    def __init__(self,train_file_path,test_file_path=None):\n",
    "        \"\"\"\n",
    "        Funci√≥n que inicializa la clase con la ruta el archivo y verifica\n",
    "        que exista.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        file_path: str\n",
    "            Ruta del archivo csv\n",
    "\n",
    "        Raise\n",
    "        FileNotFoundError\n",
    "            Si el archivo no existe.\n",
    "        \"\"\"\n",
    "        self.train_file_path = Path(train_file_path)\n",
    "        self.test_file_path = Path(test_file_path) if test_file_path else None\n",
    "        if not self.train_file_path.exists():\n",
    "            raise FileNotFoundError(f\"No existe la ruta {self.train_file_path}\")\n",
    "\n",
    "        if self.test_file_path and not self.test_file_path.exists():\n",
    "            raise FileNotFoundError(f\"No existe la ruta {self.test_file_path}\")\n",
    "        \n",
    "        self.data = None\n",
    "        self.test_data =None\n",
    "        self.pipeline = None\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        Lee el archivo csv de entrenamiento indicado en el self.train_file_path y lo carga como un\n",
    "        dataframe de pandas.\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            DataFrame que contiene los datos leidos del archivo csv.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        pandas.errors.EmptyDataError\n",
    "            Si el archivo est√° vac√≠o\n",
    "\n",
    "        pandas.errors.ParserError\n",
    "            Si el archivo CSV tiene errores de formato o no puede ser parseado correctamente.\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = pd.read_csv(self.train_file_path)\n",
    "        return self.data\n",
    "    \n",
    "    def load_test_dataset(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Carga el dataset de test (si se proporcion√≥).\n",
    "\n",
    "        return\n",
    "        ------\n",
    "        pd.DataFrame\n",
    "            DataFrame que contiene los datos leidos del archivo csv.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            Si no se proporciona la ruta del dataset de prueba\n",
    "        \n",
    "        pandas.errors.EmptyDataError\n",
    "            Si el archivo est√° vac√≠o\n",
    "\n",
    "        pandas.errors.ParserError\n",
    "            Si el archivo CSV tiene errores de formato o no puede ser parseado correctamente.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.test_file_path is None:\n",
    "            raise ValueError(\"No se proporcion√≥ la ruta del dataset de test.\")\n",
    "        self.test_data = pd.read_csv(self.test_file_path)\n",
    "\n",
    "        return self.test_data\n",
    "    \n",
    "    def train_pipeline(self, target ='default_12m',parameters = None):\n",
    "        \"\"\"\n",
    "        Entrena un pipeline con RobustScaler y DecisionTreeClassifier\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        target: str\n",
    "            Nombre de la columna objetivo, por decfecto es 'defaul_12m'\n",
    "\n",
    "        parameters: dict\n",
    "            Diccionario con los mejores par√°metros para entrenar el modelo\n",
    "\n",
    "        Raise\n",
    "        -----\n",
    "        ValueError\n",
    "            Si la variable target no existe en el dataset\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        sklearn.pipeline\n",
    "            pipeline de skalearn entrenada\n",
    "\n",
    "        \"\"\"\n",
    "        if target not in self.data.columns:\n",
    "            raise ValueError(f\"La variable objetivo '{target}' no se encuentra en los datos.\")\n",
    "        \n",
    "        independientes = self.data.drop(columns=[target],axis=1)\n",
    "        objetivo = self.data[target]\n",
    "\n",
    "        parameters = parameters or {}\n",
    "        pipeline = Pipeline([ \n",
    "            ('scaler',RobustScaler()), \n",
    "            ('classifier',DecisionTreeClassifier(**parameters)) ])\n",
    "\n",
    "        pipeline.fit(independientes, objetivo)\n",
    "        self.pipeline = pipeline\n",
    "    \n",
    "        return pipeline\n",
    "    \n",
    "    def test_pipeline(self,target = 'default_12m',pos_label=1,print_metrics=True):\n",
    "        \"\"\"\n",
    "        Se encarga de evaluar el modelo entrenado\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        target: str\n",
    "            Nombre de la columna objetivo, por decfecto es 'defaul_12m'\n",
    "\n",
    "        pos_label: int\n",
    "            Clase que se considera positiva, por defecto es 1\n",
    "\n",
    "        print_metrics: Booleano\n",
    "            Indica si desea imprimir m√©tricas de rendimiento\n",
    "        \n",
    "        Raises\n",
    "        ------\n",
    "        ValueError\n",
    "            Si los datos de test no est√°n cargados, si el pipeline no est√° entrenado y si \n",
    "            la variable objetivo no est√° en los datos de test.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        dict\n",
    "            Diccionario con las m√©tricas de evaluaci√≥n del modelo\n",
    "\n",
    "        \"\"\"\n",
    "        if self.pipeline is None:\n",
    "            raise ValueError(\"El pipeline no est√° entrenado. Ejecuta primero 'train_pipeline()'.\")\n",
    "        if self.test_data is None:\n",
    "            raise ValueError(\"Los datos de test no est√°n cargados. Ejecuta 'load_test_dataset()'.\")\n",
    "        if target not in self.test_data.columns:\n",
    "            raise ValueError(f\"La variable objetivo '{target}' no se encuentra en los datos de test.\")\n",
    "        \n",
    "        X_test = self.test_data.drop(columns=[target])\n",
    "        y_test = self.test_data[target]\n",
    "        \n",
    "        y_pred = self.pipeline.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, pos_label=pos_label)\n",
    "        precision = precision_score(y_test, y_pred, pos_label=pos_label)\n",
    "        recall = recall_score(y_test, y_pred, pos_label=pos_label)\n",
    "\n",
    "        metrics = {\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "            }\n",
    "        \n",
    "        if print_metrics:\n",
    "            print(\"=== M√âTRICAS DEL MODELO ===\")\n",
    "            print(f\"F1-Score: {f1:.4f}\")\n",
    "            print(f\"Precisi√≥n: {precision:.4f}\")\n",
    "            print(f\"Recall: {recall:.4f}\")\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ba1d86",
   "metadata": {},
   "source": [
    "Veamos el funcionamieno de la clase TrainModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d6616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== M√âTRICAS DEL MODELO ===\n",
      "F1-Score: 0.8000\n",
      "Precisi√≥n: 0.8000\n",
      "Recall: 0.8000\n"
     ]
    }
   ],
   "source": [
    "project_root = next(p for p in Path.cwd().parents if (p / 'data').exists())\n",
    "file_path = lambda file: os.path.join(project_root,'data/processed',file)\n",
    "\n",
    "train_model = TrainModel(\n",
    "    train_file_path=file_path('covalto_sme_credit_train.csv'),\n",
    "    test_file_path=file_path('covalto_sme_credit_test.csv')\n",
    ")\n",
    "train_model.load_dataset()\n",
    "train_model.load_test_dataset()\n",
    "\n",
    "modelo = train_model.train_pipeline(\n",
    "    target = 'default_12m',\n",
    "    parameters = {\n",
    "        'criterion': 'gini', \n",
    "        'max_depth': 2, \n",
    "        'min_samples_split': 8, \n",
    "        'min_samples_leaf': 19, \n",
    "        'max_features': None, \n",
    "        'class_weight': None}\n",
    ")\n",
    "\n",
    "metrics = train_model.test_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, os\n",
    "\n",
    "joblib.dump(modelo, os.path.join(project_root, \"test_pipeline.pkl\"))\n",
    "print(\"‚úÖ Pipeline serializado correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39577b",
   "metadata": {},
   "source": [
    "Perfecto, este modelo ofrece un rendimiento satisfactorio. El siguiente paso consiste en crear la clase encargada de generar el bucket llamado mlflow en MinIO, el cual se utilizar√° para almacenar los artefactos generados por MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe495725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "class MinioMlflowBucketCreator:\n",
    "    \"\"\"\n",
    "    Se conecta a minio y puede crear buckest\n",
    "    \"\"\"\n",
    "    def __init__(self,credential_path):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.credential_path = Path(credential_path)\n",
    "        if not self.credential_path.exists():\n",
    "            raise FileNotFoundError(f\"No existe la ruta {self.credential_path}\")\n",
    "        self.credentials = None\n",
    "        self.client = None\n",
    "\n",
    "    def load_minio_credentials(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        with open(self.credential_path, 'r') as file:\n",
    "            self.credentials = json.load(file)\n",
    "        return self.credentials\n",
    "    \n",
    "    def conection_minio(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        s3 = boto3.client(\n",
    "            \"s3\",\n",
    "            endpoint_url = self.credentials['endpoint_url'],\n",
    "            aws_access_key_id = self.credentials['aws_access_key_id'],\n",
    "            aws_secret_access_key = self.credentials['aws_secret_access_key']\n",
    "        )\n",
    "        self.client = s3\n",
    "        return self.client\n",
    "    \n",
    "    def create_bucket(self, bucket_name ='mlflow'):\n",
    "\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if self.client is None:\n",
    "            raise ConnectionError(\"Primero debes conectarte a MinIO con conection_minio().\")\n",
    "        try:\n",
    "            existing_buckets = [b['Name'] for b in self.client.list_buckets().get('Buckets', [])]\n",
    "            if bucket_name not in existing_buckets:\n",
    "                self.client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            raise RuntimeError(f\"Error al crear el bucket {bucket_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb7cab",
   "metadata": {},
   "source": [
    "Porbemos el c√≥digo para ver si tenemos exito en la conexi√≥n con minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9833ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_secrets = next(p for p in Path.cwd().parents if (p / 'secrets').exists())\n",
    "credential_path = lambda file: os.path.join(project_root,'secrets',file)\n",
    "minio = MinioMlflowBucketCreator(\n",
    "    credential_path = credential_path('credentials_minio.json')\n",
    ")\n",
    "minio.load_minio_credentials()\n",
    "minio.conection_minio()\n",
    "minio.create_bucket(bucket_name='mlflow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c29ade3",
   "metadata": {},
   "source": [
    "Perfecto, ahora que ya contamos con la clase encargada de crear los buckets en MinIO, debemos proceder a implementar la clase responsable de cargar los modelos entrenados en MLflow y registrarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59afc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "from datetime import datetime\n",
    "\n",
    "class MLflowModelRegister:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,tracking_uri_path):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.tracking_uri_path = Path(tracking_uri_path)\n",
    "        if not self.tracking_uri_path.exists():\n",
    "            raise FileNotFoundError(f\"No existe la ruta {self.tracking_uri_path}\")\n",
    "        self.tracking_uri = None\n",
    "    \n",
    "    def load_tracking_uri_mlflow(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        with open(self.tracking_uri_path, 'r') as file:\n",
    "            self.tracking_uri = json.load(file)\n",
    "        return self\n",
    "        \n",
    "    def create_mlflow_experiment(self, experiment_name = \"Experimento_1\"):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        tracking_uri = self.tracking_uri['tracking_uri']\n",
    "        mlflow.set_tracking_uri(tracking_uri)\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        return self\n",
    "\n",
    "    def log_pipeline(\n",
    "        self,\n",
    "        pipeline,\n",
    "        metrics: dict,\n",
    "        params: dict,\n",
    "        model_name: str = \"sklearn-pipeline\",\n",
    "        framework: str = \"scikit-learn\",\n",
    "        type: str = \"classification\",\n",
    "        tags: dict = None\n",
    "    ):\n",
    "        run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            if params:\n",
    "                mlflow.log_params(params)                           #Registrar par√°metros\n",
    "\n",
    "            if metrics:\n",
    "                mlflow.log_metrics(metrics)                         # Registrar m√©tricas\n",
    "            \n",
    "            mlflow.sklearn.log_model(pipeline, artifact_path=model_name)     # Registrar pipeline\n",
    "\n",
    "            # Registrar tags descriptivos\n",
    "            mlflow.set_tag(\"model_name\", model_name)\n",
    "            mlflow.set_tag(\"framework\", framework)\n",
    "            mlflow.set_tag(\"type\", type)\n",
    "\n",
    "            # Para tags en diccionarios\n",
    "            if tags:\n",
    "                for k, v in tags.items():\n",
    "                    mlflow.set_tag(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b9697",
   "metadata": {},
   "source": [
    "Veamos si se carga el modelo a mlflow y a minio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d30ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri_path = lambda file: os.path.join(project_root,'secrets',file)\n",
    "\n",
    "mlflow_register = MLflowModelRegister(\n",
    "    tracking_uri_path = tracking_uri_path ('tracking_uri_mlflow.json')\n",
    ")\n",
    "\n",
    "\n",
    "mlflow_register = mlflow_register.load_tracking_uri_mlflow()\n",
    "mlflow_register = mlflow_register.create_mlflow_experiment(\n",
    "    experiment_name = \"riesgo_crediticio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d6e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/01 18:50:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/11/01 18:50:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run DecisionTree_CreditRiskModel_20251101_185049 at: http://localhost:5000/#/experiments/1/runs/e3c6ceecb6574beb9fb8a0f19acc7f6e\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:6000\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio_123\"\n",
    "\n",
    "mlflow_register = mlflow_register.log_pipeline(\n",
    "    pipeline = modelo,\n",
    "    metrics = metrics,\n",
    "    params={\n",
    "    'criterion': 'gini', \n",
    "    'max_depth': 2, \n",
    "    'min_samples_split': 8, \n",
    "    'min_samples_leaf': 19, \n",
    "    'max_features': None, \n",
    "    'class_weight': None},\n",
    "    model_name = \"DecisionTree_CreditRiskModel\",\n",
    "    tags={\"author\": \"Luis Garcia\", \"use_case\": \"credit-risk\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d78d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "from datetime import datetime\n",
    "\n",
    "class MLflowModelRegister:\n",
    "    \"\"\"\n",
    "    Configura un cliente para interacturar con MLflow. El prop√≥sito general\n",
    "    es inicializar un objeto para gestionar experimentos y modelos de MLflow.\n",
    "    \"\"\"\n",
    "    def __init__(self, tracking_uri=None, experiment_name=\"default_experiment\"):\n",
    "\n",
    "        self.tracking_uri = tracking_uri or os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\")\n",
    "        self.experiment_name = experiment_name\n",
    "\n",
    "        # Configuraci√≥n de MLflow\n",
    "        mlflow.set_tracking_uri(self.tracking_uri)\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "        self.client = MlflowClient(tracking_uri=self.tracking_uri)\n",
    "        \n",
    "\n",
    "    def log_pipeline(\n",
    "        self,\n",
    "        pipeline,\n",
    "        metrics: dict,\n",
    "        params: dict,\n",
    "        model_name: str = \"sklearn-pipeline\",\n",
    "        tags: dict = None\n",
    "    ):\n",
    "        run_name = f\"{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name):\n",
    "            if params:\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "            if metrics:\n",
    "                mlflow.log_metrics(metrics)\n",
    "            \n",
    "            # === Registrar el pipeline ===\n",
    "            mlflow.set_tag(\"model_name\", model_name)\n",
    "            mlflow.set_tag(\"framework\", \"scikit-learn\")\n",
    "            mlflow.set_tag(\"type\", \"classification\")\n",
    "\n",
    "            if tags:\n",
    "                for k, v in tags.items():\n",
    "                    mlflow.set_tag(k, v)\n",
    "            \n",
    "            mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")\n",
    "            run_id = mlflow.active_run().info.run_id\n",
    "        return run_id\n",
    "\n",
    "    def register_models_in_registry(self, model_names: list):\n",
    "        \"\"\"\n",
    "        Registra los modelos en el Model Registry y los promueve a Production.\n",
    "        Busca el run m√°s reciente asociado a cada 'model_name'.\n",
    "        \"\"\"\n",
    "        for model_name in model_names:\n",
    "            try:\n",
    "                # Buscar el run m√°s reciente por tag\n",
    "                runs = mlflow.search_runs(\n",
    "                    filter_string=f\"tags.model_name = '{model_name}'\",\n",
    "                    order_by=[\"start_time DESC\"]\n",
    "                )\n",
    "\n",
    "                if runs.empty:\n",
    "                    print(f\"No se encontr√≥ ning√∫n run con tag model_name = '{model_name}'\")\n",
    "                    continue\n",
    "\n",
    "                run_id = runs.iloc[0][\"run_id\"]\n",
    "                model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "                # Registrar modelo en el Model Registry\n",
    "                registered_model = mlflow.register_model(\n",
    "                    model_uri=model_uri,\n",
    "                    name=model_name\n",
    "                )\n",
    "\n",
    "                version = registered_model.version\n",
    "                print(f\"Modelo {model_name} registrado como versi√≥n {version}\")\n",
    "\n",
    "                # Transicionar la versi√≥n a Production\n",
    "                self.client.transition_model_version_stage(\n",
    "                    name=model_name,\n",
    "                    version=version,\n",
    "                    stage=\"Production\",\n",
    "                    archive_existing_versions=True\n",
    "                )\n",
    "\n",
    "                print(f\"Modelo {model_name} versi√≥n {version} promovido a 'Production'\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error registrando o promoviendo {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cc8f9",
   "metadata": {},
   "source": [
    "Probando el c√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85cd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registrar el modelo en MLflow\n",
    "mlflow_logger = MLflowModelRegister(\n",
    "    tracking_uri=\"http://localhost:5000\",\n",
    "    experiment_name=\"riesgo_crediticio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2964a9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = mlflow_logger.log_pipeline(\n",
    "    pipeline=modelo ,\n",
    "    metrics=metrics,\n",
    "    params={\n",
    "        'criterion': 'gini', \n",
    "        'max_depth': 2, \n",
    "        'min_samples_split': 8, \n",
    "        'min_samples_leaf': 19, \n",
    "        'max_features': None, \n",
    "        'class_weight': None},\n",
    "    model_name=\"DecisionTreeCreditModel\",\n",
    "    tags={\"author\": \"Luis Garcia\", \"use_case\": \"credit-risk\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger.register_models_in_registry([\"DecisionTreeCreditModel\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
